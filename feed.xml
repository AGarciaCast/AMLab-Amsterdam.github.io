<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://amlab-amsterdam.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://amlab-amsterdam.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-03-28T11:53:23+00:00</updated><id>https://amlab-amsterdam.github.io/feed.xml</id><title type="html">blank</title><subtitle>Amsterdam Machine Learning Lab, Informatics Institute, University of Amsterdam 
</subtitle><entry><title type="html">AMLab Papers at ICML 2022</title><link href="https://amlab-amsterdam.github.io/blog/2022/icml/" rel="alternate" type="text/html" title="AMLab Papers at ICML 2022" /><published>2022-07-19T07:00:00+00:00</published><updated>2022-07-19T07:00:00+00:00</updated><id>https://amlab-amsterdam.github.io/blog/2022/icml</id><content type="html" xml:base="https://amlab-amsterdam.github.io/blog/2022/icml/"><![CDATA[<p><img src="https://icml.cc/static/core/img/ICML-logo.svg" alt="ICML 2022" /></p>

<p>AMLab members will be presenting 8 papers at ICML 2022 main conference:</p>

<ol>
  <li>
    <p><strong>Equivariant diffusion for molecule generation in 3d (oral)</strong> <br />
<em>Hoogeboom, Emiel, Satorras, Vı́ctor Garcia, Vignac, Clément, and Welling, Max</em> <br />
[<a href="https://icml.cc/virtual/2022/oral/16254">Conference page</a>, <a href="https://arxiv.org/pdf/2203.17003">PDF</a>, <a href="https://github.com/ehoogeboom/e3_diffusion_for_molecules">GitHub</a>]</p>
  </li>
  <li>
    <p><strong>Lie Point Symmetry Data Augmentation for Neural PDE Solvers (spotlight)</strong> <br />
<em>Brandstetter, Johannes, Welling, Max, and Worrall, Daniel E</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/17314">Conference page</a>, <a href="https://arxiv.org/pdf/2202.07643">PDF</a>, <a href="https://github.com/brandstetter-johannes/LPSDA">GitHub</a>]</p>
  </li>
  <li>
    <p><strong>Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups (spotlight)</strong> <br />
<em>Knigge, David M, Romero, David W, and Bekkers, Erik J</em><br />
[<a href="https://icml.cc/virtual/2022/spotlight/17826">Conferende page</a>, <a href="https://arxiv.org/pdf/2110.13059.pdf">PDF</a>, <a href="https://github.com/david-knigge/separable-group-convolutional-networks">GitHub</a>]</p>
  </li>
  <li>
    <p><strong>CITRIS: Causal Identifiability from Temporal Intervened Sequences (spotlight)</strong> <br />
<em>Lippe, Phillip, Magliacane, Sara, Löwe, Sindy, Asano, Yuki M, Cohen, Taco, and Gavves, Efstratios</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/17426">Conferende page</a>, <a href="https://arxiv.org/pdf/2202.03169.pdf">PDF</a>, <a href="https://github.com/phlippe/CITRIS">GitHub</a>]</p>
  </li>
  <li>
    <p><strong>Learning Symmetric Embeddings for Equivariant World Models (spotlight)</strong> <br />
<em>Park, Jung Yeon, Biza, Ondrej, Zhao, Linfeng, Meent, Jan-Willem, and Walters, Robin</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/17396">Conferende page</a>, <a href="https://arxiv.org/pdf/2204.11371.pdf">PDF</a>]</p>
  </li>
  <li>
    <p><strong>Adapting the Linearised Laplace Model Evidence for Modern Deep Learning (spotlight)</strong> <br />
<em>Antoran, Javier, Janz, David, Allingham, James Urquhart, Daxberger, Erik, Barbano, Riccardo, Nalisnick, Eric, and Hernandez-Lobato, Jose Miguel</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/18290">Conferende page</a>, <a href="https://edaxberger.github.io/papers/Adapting%20the%20Linearised%20Laplace%20Model%20Evidence%20for%20Modern%20Deep%20Learning.pdf">PDF</a>]</p>
  </li>
  <li>
    <p><strong>Calibrated Learning to Defer with One-vs-All Classifiers (spotlight)</strong> <br />
<em>Verma, Rajeev, and Nalisnick, Eric</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/18124">Conferende page</a>, <a href="https://arxiv.org/pdf/2202.03673">PDF</a>]</p>
  </li>
  <li>
    <p><strong>Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models and Amortized Policy Search (spotlight)</strong> <br />
<em>Wang, Q., and Hoof, H.</em> <br />
[<a href="https://icml.cc/virtual/2022/spotlight/17730">Conferende page</a>, <a href="https://arxiv.org/abs/2102.08291">PDF</a>]</p>
  </li>
</ol>]]></content><author><name>Erik Bekkers</name></author><summary type="html"><![CDATA[Read here about the 8 papers that AMLab members will be presenting at ICML this year.]]></summary></entry><entry><title type="html">AMLab Papers at ICLR 2022</title><link href="https://amlab-amsterdam.github.io/blog/2022/iclr/" rel="alternate" type="text/html" title="AMLab Papers at ICLR 2022" /><published>2022-04-25T07:00:00+00:00</published><updated>2022-04-25T07:00:00+00:00</updated><id>https://amlab-amsterdam.github.io/blog/2022/iclr</id><content type="html" xml:base="https://amlab-amsterdam.github.io/blog/2022/iclr/"><![CDATA[<p><img src="https://iclr.cc/static/core/img/ICLR-logo.svg" alt="ICLR 2022" /></p>

<p>AMLab members will be presenting 6 papers at ICLR 2022 main conference:</p>

<ol>
  <li>
    <p><strong>Geometric and Physical Quantities improve E(3) Equivariant Message Passing (spotlight)</strong> <br />
<em>Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J Bekkers, Max Welling</em> <br />
[<a href="https://openreview.net/forum?id=_xwr8gOBeV1">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/6225">Poster Session</a>, <a href="https://robdhess.github.io/Steerable-E3-GNN/">Blog</a>]</p>
  </li>
  <li>
    <p><strong>Message Passing Neural PDE Solvers (spotlight)</strong> <br />
<em>Johannes Brandstetter, Daniel E. Worrall, Max Welling</em><br />
[<a href="https://openreview.net/forum?id=vSix3HPYKSU">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/7134">Poster Session</a>]</p>
  </li>
  <li>
    <p><strong>Multi-Agent MDP Homomorphic Networks</strong> <br />
<em>Elise van der Pol, Herke van Hoof, Frans A Oliehoek, Max Welling</em> <br />
[<a href="https://openreview.net/forum?id=H7HDG--DJF0">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/6821">Poster Session</a>]</p>
  </li>
  <li>
    <p><strong>FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes</strong> <br />
<em>David W. Romero, Robert-Jan Bruintjes, Jakub Mikolaj Tomczak, Erik J Bekkers, Mark Hoogendoorn, Jan van Gemert</em> <br />
[<a href="https://openreview.net/forum?id=3jooF27-0Wy">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/6763">Poster Session</a>]</p>
  </li>
  <li>
    <p><strong>CKConv: Continuous Kernel Convolution For Sequential Data</strong> <br />
<em>David W. Romero, Anna Kuzina, Erik J Bekkers, Jakub Mikolaj Tomczak, Mark Hoogendoorn</em> <br />
[<a href="https://openreview.net/forum?id=8FhxBtXSl0">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/6393">Poster Session</a>]</p>
  </li>
  <li>
    <p><strong>Self-Supervised Inference in State-Space Models</strong> <br />
<em>David Ruhe, Patrick Forré</em> <br />
[<a href="https://openreview.net/forum?id=VPjw9KPWRSK">OpenReview</a>, <a href="https://iclr.cc/virtual/2022/poster/6606">Poster Session</a>]</p>
  </li>
</ol>]]></content><author><name>Jan-Willem van de Meent</name></author><summary type="html"><![CDATA[Read here about the 6 papers that AMLab members will be presenting at ICLR this year.]]></summary></entry><entry><title type="html">Steerable E(3)-Equivariant Graph Neural Networks</title><link href="https://amlab-amsterdam.github.io/blog/2022/segnn/" rel="alternate" type="text/html" title="Steerable E(3)-Equivariant Graph Neural Networks" /><published>2022-04-05T07:00:00+00:00</published><updated>2022-04-05T07:00:00+00:00</updated><id>https://amlab-amsterdam.github.io/blog/2022/segnn</id><content type="html" xml:base="https://amlab-amsterdam.github.io/blog/2022/segnn/"><![CDATA[<p>A new <a href="https://arxiv.org/abs/2110.02905">publication</a> by Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J Bekkers and Max Welling introduces the steerable E(3)-equivariant graph neural network, or SEGNN. This model uses irreducible representations of the orthogonal group O(3) to condition messages on relative positions and other geometric attributes and achieves excellent results on QM9 and the Open Catalyst Project. Accompanying the paper is a <a href="https://robdhess.github.io/Steerable-E3-GNN/">blog post</a> that explains how to build O(3) steerable networks and showcases some of the benefits of equivariant message passing. The paper was awarded a spotlight at ICLR 2022.</p>

<p><img src="https://raw.githubusercontent.com/RobDHess/Steerable-E3-GNN/gh-pages/assets/forward_pass_faster_larger.gif" alt="SEGNN" /></p>]]></content><author><name>Rob Hesselink</name></author><summary type="html"><![CDATA[Read about our work on E(3)-steerable graph neural networks for molecular data.]]></summary></entry><entry><title type="html">Blogging on Bayes</title><link href="https://amlab-amsterdam.github.io/blog/2021/TimBayes/" rel="alternate" type="text/html" title="Blogging on Bayes" /><published>2021-04-07T07:00:00+00:00</published><updated>2021-04-07T07:00:00+00:00</updated><id>https://amlab-amsterdam.github.io/blog/2021/TimBayes</id><content type="html" xml:base="https://amlab-amsterdam.github.io/blog/2021/TimBayes/"><![CDATA[<p>Tim Bakker’s musings on Bayesianism, following the AMLab reading group on E.T. Jaynes’ book <em><a href="https://bayes.wustl.edu/etj/prob/book.pdf">Probability Theory: The Logic of Science</a></em>.</p>

<p>Posts:</p>
<ol>
  <li>
    <p><a href="https://www.tbbakker.nl/post/bayes_commentary/">A look at the objective Bayesian prescription for reasoning under uncertainty.</a></p>
  </li>
  <li>
    <p><a href="https://www.tbbakker.nl/post/bayes_ml/">A tour from prescriptive Bayesianism to modern statistical machine learning.</a></p>
  </li>
</ol>]]></content><author><name>Tim Bakker</name></author><summary type="html"><![CDATA[Musings on the objective Bayesian prescription for reasoning under uncertainty and statistical machine learning.]]></summary></entry><entry><title type="html">Putting an End to End-to-End</title><link href="https://amlab-amsterdam.github.io/blog/2020/GreedyInfoMax/" rel="alternate" type="text/html" title="Putting an End to End-to-End" /><published>2020-04-12T07:00:00+00:00</published><updated>2020-04-12T07:00:00+00:00</updated><id>https://amlab-amsterdam.github.io/blog/2020/GreedyInfoMax</id><content type="html" xml:base="https://amlab-amsterdam.github.io/blog/2020/GreedyInfoMax/"><![CDATA[<p>In our paper <a href="https://arxiv.org/abs/1905.11786">Putting An End to End-to-End: Gradient-Isolated Learning of Representations (S. Löwe, P. O’Connor, B. S. Veeling)</a>, we showed that we can train a neural network without end-to-end backpropagation and achieve competitive performance. For this, we received an Honorable Mention for Outstanding New Directions Paper Award at NeurIPS 2019.</p>

<p>Find out more about this paper in <strong><a href="https://loewex.github.io/GreedyInfoMax.html">this blog-post</a></strong> by Sindy Löwe.</p>]]></content><author><name>Sindy Löwe</name></author><summary type="html"><![CDATA[Find out more about how we can train a neural network without end-to-end backpropagation and achieve competitive performance.]]></summary></entry></feed>