@article{boelrijk2022predicting,
  title={Predicting RP-LC retention indices of structurally unknown chemicals from mass spectrometry data},
  author={Boelrijk, Jim and van Herwerden, Denice and Samanipour, Saer  and Ensing, Bernd and Forr{\'e}, Patrick},
  year={2023},
  journal={Journal of Cheminformatics},
  html={https://jcheminf.biomedcentral.com/articles/10.1186/s13321-023-00699-8},
  abstract={Non-target analysis combined with high resolution mass spectrometry is considered one of the most comprehensive strategies for the detection and identification of known and unknown chemicals in complex samples. However, many compounds remain unidentified due to data complexity and limited structures in chemical databases. In this work, we have developed and validated a novel machine learning algorithm to predict the retention index (r$_i$) values for structurally (un)known chemicals based on their measured fragmentation pattern. The developed model, for the first time, enabled the predication of r$_i$ values without the need for the exact structure of the chemicals, with an $R^2$ of 0.91 and 0.77 and root mean squared error (RMSE) of 47 and 67 r$_i$ units for the Norman and amide test set, respectively. This fragment based model showed comparable accuracy in r$_i$ prediction compared to conventional descriptor-based models that rely on known chemical structure, which obtained a $R^2$ of 0.85 with and RMSE of 67.},
}

@inproceedings{boelrijk2023multiobjective,
  title={Multi-objective optimization via equivariant deep hypervolume approximation},
  author={Boelrijk, Jim and Ensing, Bernd and Forr{\'e}, Patrick},
  year={2023},
  booktitle={International Conference on Learning Representations, {ICLR}},
  abbr={ICLR},
  html={http://arxiv.org/abs/2210.02177},
  abstract={Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. To overcome these restrictions we propose to approximate the hypervolume function with a deep neural network, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale-equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks.}
}


@article{boelrijk2023closedloop,
  title={Closed-loop automatic gradient design for liquid chromatography using Bayesian optimization},
  author={Boelrijk, Jim and Ensing, Bernd and Forr{\'e}, Patrick and Pirok, Bob},
  year={2023},
   journal={Analytica Chimica Acta},
     abstract={Contemporary complex samples require sophisticated methods for full analysis. This work describes the development of a Bayesian optimization algorithm for the automated and unsupervised development of gradient programs. The algorithm was tailored to LC using a Gaussian process model with a novel covariance kernel. To facilitate unsupervised learning, the algorithm was designed to interface directly with the chromatographic system. Single-objective and multi-objective Bayesian optimization strategies were investigated for the separation of a complex (n>80) dye mixture. The multi-objective strategy was found to be very powerful and flexible in terms of exploring the Pareto front. The single-objective strategy was found to be slightly faster in finding a satisfactory optimum. One additional advantage of the multi-objective approach was that it allows a trade-off to be made between multiple objectives. In general, the Bayesian optimization strategy was found to be particularly suitable, but not limited to, cases where retention modelling is not possible, although its scalability might be limited in terms of the number of parameters that can be simultaneously optimized.},
  html={https://doi.org/10.1016/j.aca.2023.340789}
}

@article{bos2022chemometric,
  title={Chemometric Strategies for Fully Automated Interpretive Method Development in Liquid Chromatography},
  author={Bos, Tijmen and Boelrijk, Jim and Molenaar, Stef and van't Veer, Brian and Niezen, Leon and van Herwerden, Denice and Samanipour, Saer and Stoll, Dwight and Forr{\'e}, Patrick and Ensing, Bernd and Somsen, Govert and Pirok, Bob},
  year={2022},
  journal={Analytical Chemistry},
    abstract={The great potential gains in separation power and analysis time that can result from rigorously optimizing LC-MS and 2D-LC-MS methods for routine measurements has prompted many scientists to develop computer-aided method-development tools. The applicability of these has been proven in numerous applications, but their proliferation is still limited. Arguably, the majority of LC methods are still developed in a conventional manner, i.e. by analysts who rely on their knowledge and experience. In this work, a novel, open-source algorithm was developed for automated and interpretive method development of LC separations. A closed-loop workflow was constructed that interacted directly with the LC and ran unsupervised in an automated fashion. The algorithm was tested using two newly designed strategies. The first utilized retention modeling, whereas the second used the Bayesian-optimization machine-learning approach. In both cases, the algorithm could arrive within ten iterations at an optimum of the objective function, which included resolution and measurement time. The design of the algorithm was modular, so as to facilitate compatibility with previous works in literature and its performance thus hinged on each module (e.g., signal processing, choice of retention model, objective function). Key focus areas for further improvement were identified. Bayesian optimization did not require any peak tracking or retention modeling. Accurate prediction of elution profiles was found to be indispensable for the strategy using retention modeling. This is the first interpretive algorithm demonstrated with complex samples. Peak tracking was conducted using UV-Vis absorbance detection, but use of MS detection is expected to significantly broaden the applicability of the workflow.},
  html={https://doi.org/10.1021/acs.analchem.2c03160}
}

@article{boelrijk2021bayesian,
  title={Bayesian optimization of comprehensive two-dimensional liquid chromatography separations},
  author={Boelrijk, Jim and Pirok, Bob and Ensing, Bernd and Forr{\'e}, Patrick},
  journal={Journal of Chromatography A},
  volume={1659},
  pages={462628},
  year={2021},
  publisher={Elsevier},
  abstract={Comprehensive two-dimensional liquid chromatography (LCxLC), is a powerful, emerging separation technique in analytical chemistry. However, as many instrumental parameters need to be tuned, the technique is troubled by lengthy method development. To speed up this process, we applied a Bayesian optimization algorithm. The algorithm can optimize LCxLC method parameters by maximizing a novel chromatographic response function based on the concept of connected components of a graph. The algorithm was benchmarked against a grid search (11,664 experiments) and a random search algorithm on the optimization of eight gradient parameters for four different samples of 50 compounds. The worst-case performance of the algorithm was investigated by repeating the optimization loop for 100 experiments with random starting experiments and seeds. Given an optimization budget of 100 experiments, the Bayesian optimization algorithm generally outperformed the random search and often improved upon the grid search. Moreover, the Bayesian optimization algorithm offered a considerably more sample-efficient alternative to grid searches, as it found similar optima to the grid search in far fewer experiments (a factor of 16–100 times less). This could likely be further improved by a more informed choice of the initialization experiments, which could be provided by the analyst’s experience or smarter selection procedures. The algorithm allows for expansion to other method parameters (e.g., temperature, flow rate, etc.) and unlocks closed-loop automated method development.},
html={https://doi.org/10.1016/j.chroma.2021.462628}
}
