@inproceedings{cscnns,
  title = {Clifford-Steerable Convolutional Neural Networks},
  author = {Zhdanov, Maksim and Ruhe, David and Weiler, Maurice and Lucic, Ana and Brandstetter, Johannes and Forré, Patrick},
  url = {https://arxiv.org/abs/2402.14730},
  year = 2024,
  month = 3,
  booktitle = {ICML 2024},
  abbr = {ICML},
  keywords = {},
  pubstate = {published},
  tppubtype = {inproceedings},
  abstract = {We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a novel class of \(E(p, q)\)-equivariant CNNs. CS-CNNs process multivector fields on pseudo-Euclidean spaces. They cover, for instance, \(E(3)\)-equivariance and Poincaré-equivariance on Minkowski spacetime. Our approach is based on an implicit parametrization of \(O(p,q)\)-steerable kernels via Clifford group equivariant neural networks. We significantly and consistently outperform baseline methods on fluid dynamics as well as relativistic electrodynamics forecasting tasks.},
  url = {https://arxiv.org/abs/2402.14730},
  code = {https://github.com/maxxxzdn/clifford-group-equivariant-cnns},
  blog = {/blog/cscnns.html},
}

@article{https://doi.org/10.48550/arxiv.2212.06096,
  doi = {10.48550/ARXIV.2212.06096},
  abbr = {NeurIPS},
  abstract = {Steerable convolutional neural networks (CNNs) provide a general framework for building neural networks equivariant to translations and other transformations belonging to an origin-preserving group G, such as reflections and rotations. They rely on standard convolutions with G-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group G, the implementation of a kernel basis does not generalize to other symmetry transformations, which complicates the development of group equivariant models. We propose using implicit neural representation via multi-layer perceptrons (MLPs) to parameterize G-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable CNNs and generalizes to any group G for which a G-equivariant MLP can be built. We apply our method to point cloud (ModelNet-40) and molecular data (QM9) and demonstrate a significant improvement in performance compared to standard Steerable CNNs.},
  url = {https://arxiv.org/abs/2212.06096},
  journal={NeurIPS 2023},
  arxiv = {2212.06096},
  pdf = {https://arxiv.org/pdf/2212.06096.pdf},
  url = {https://arxiv.org/abs/2212.06096},
  author = {Zhdanov, Maksim and Hoffmann, Nico and Cesa, Gabriele},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Implicit Neural Convolutional Kernels for Steerable CNNs},
  publisher = {arXiv},
  copyright = {Creative Commons Attribution 4.0 International},
  preview = {imp_kernels.png},
  code = {https://github.com/maxxxzdn/implicit-steerable-kernels},
  blog = {/blog/implicit_kernels.html},
  year = 2023,
}

@article{https://doi.org/10.48550/arxiv.2206.01930,
  doi = {10.48550/ARXIV.2206.01930},
  abbr = {ICPR},
  journal={ICPR 2022},
  abstract = {Functional connectivity plays an essential role in modern neuroscience. The modality sheds light on the brain's functional and structural aspects, including mechanisms behind multiple pathologies. One such pathology is schizophrenia which is often followed by auditory verbal hallucinations. The latter is commonly studied by observing functional connectivity during speech processing. In this work, we have made a step toward an in-depth examination of functional connectivity during a dichotic listening task via deep learning for three groups of people: schizophrenia patients with and without auditory verbal hallucinations and healthy controls. We propose a graph neural network-based framework within which we represent EEG data as signals in the graph domain. The framework allows one to 1) predict a brain mental disorder based on EEG recording, 2) differentiate the listening state from the resting state for each group and 3) recognize characteristic task-depending connectivity. Experimental results show that the proposed model can differentiate between the above groups with state-of-the-art performance. Besides, it provides a researcher with meaningful information regarding each group's functional connectivity, which we validated on the current domain knowledge.},
  url = {https://arxiv.org/abs/2206.01930},
  arxiv = {2206.01930},
  pdf = {https://arxiv.org/pdf/2206.01930.pdf},
  code = {https://github.com/maxxxzdn/EEGCN},
  author = {Zhdanov, Maksim and Steinmann, Saskia and Hoffmann, Nico},
  keywords = {Neurons and Cognition (q-bio.NC), Machine Learning (cs.LG), FOS: Biological sciences, FOS: Biological sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Investigating Brain Connectivity with Graph Neural Networks and GNNExplainer},
  publisher = {arXiv},
  copyright = {arXiv.org perpetual, non-exclusive license},
  preview = {gnns.png},
  year = 2022,
}