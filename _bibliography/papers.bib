---
---



@inproceedings{brandstetter2021geometric,
  title={Geometric and Physical Quantities improve E (3) Equivariant Message Passing},
  author={Brandstetter, Johannes and Hesselink, Rob and van der Pol, Elise and Bekkers, Erik and Welling, Max},
  booktitle={International Conference on Learning Representations},
  abbr={ICLR},
  year={2022},
  abstract={Including covariant information, such as position, force, velocity or spin is important in many tasks in computational physics and chemistry. We introduce Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariant graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. This model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions. Through the definition of steerable node attributes, the MLPs provide a new class of activation functions for general use with steerable feature fields. We discuss ours and related work through the lens of equivariant non-linear convolutions, which further allows us to pin-point the successful components of SEGNNs: non-linear message aggregation improves upon classic linear (steerable) point convolutions; steerable messages improve upon recent equivariant graph networks that send invariant messages. We demonstrate the effectiveness of our method on several tasks in computational physics and chemistry and provide extensive ablation studies.},
  html={https://openreview.net/forum?id=_xwr8gOBeV1},
  pdf={https://arxiv.org/pdf/2110.02905},
  code={https://github.com/RobDHess/Steerable-E3-GNN},
  selected=true
}


@inproceedings{bekkers2019b,
  title={B-Spline CNNs on Lie groups},
  author={Bekkers, Erik J},
  booktitle={International Conference on Learning Representations},
  abbr={ICLR},
  year={2019},
  abstract={Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups. Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory. Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory). In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups. In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra. This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions. The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important. In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.},
  html={https://openreview.net/forum?id=H1gBhkBFDH},
  pdf={https://openreview.net/pdf?id=H1gBhkBFDH},
  video={https://www.youtube.com/watch?v=rakcnrgX4oo},
  code={https://github.com/ebekkers/gsplinets},
  selected=true
}